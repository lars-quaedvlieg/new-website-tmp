@article{huh2016makes,
  title={What makes ImageNet good for transfer learning?},
  author={Huh, Minyoung and Agrawal, Pulkit and Efros, Alexei A},
  journal={arXiv preprint arXiv:1608.08614},
  year={2016}
}

@article{krishna2022downstream,
  title={Downstream datasets make surprisingly good pretraining corpora},
  author={Krishna, Kundan and Garg, Saurabh and Bigham, Jeffrey P and Lipton, Zachary C},
  journal={arXiv preprint arXiv:2209.14389},
  year={2022}
}

@article{lee2022surgical,
  title={Surgical fine-tuning improves adaptation to distribution shifts},
  author={Lee, Yoonho and Chen, Annie S and Tajwar, Fahim and Kumar, Ananya and Yao, Huaxiu and Liang, Percy and Finn, Chelsea},
  journal={arXiv preprint arXiv:2210.11466},
  year={2022}
}

@article{kumar2022fine,
  title={Fine-tuning can distort pretrained features and underperform out-of-distribution},
  author={Kumar, Ananya and Raghunathan, Aditi and Jones, Robbie and Ma, Tengyu and Liang, Percy},
  journal={arXiv preprint arXiv:2202.10054},
  year={2022}
}