<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> CS-330 Lecture 3: Black-Box Meta-Learning &amp; In-Context Learning | Lars Quaedvlieg </title> <meta name="author" content="Lars C.P.M. Quaedvlieg"> <meta name="description" content="This lecture is part of the CS-330 Deep Multi-Task and Meta Learning course, taught by Chelsea Finn in Fall 2023 at Stanford. The goal of this lecture is to learn how to implement black-box meta-learning techniques. We will also talk about a case study of GPT-3!"> <meta property="og:site_name" content="Lars Quaedvlieg"> <meta property="og:type" content="article"> <meta property="og:title" content="Lars Quaedvlieg | CS-330 Lecture 3: Black-Box Meta-Learning &amp; In-Context Learning"> <meta property="og:url" content="https://lars-quaedvlieg.github.io//blog/2024/cs330-stanford-bbml-icl/"> <meta property="og:description" content="This lecture is part of the CS-330 Deep Multi-Task and Meta Learning course, taught by Chelsea Finn in Fall 2023 at Stanford. The goal of this lecture is to learn how to implement black-box meta-learning techniques. We will also talk about a case study of GPT-3!"> <meta property="og:image" content="/assets/img/profile.png"> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="CS-330 Lecture 3: Black-Box Meta-Learning &amp; In-Context Learning"> <meta name="twitter:description" content="This lecture is part of the CS-330 Deep Multi-Task and Meta Learning course, taught by Chelsea Finn in Fall 2023 at Stanford. The goal of this lecture is to learn how to implement black-box meta-learning techniques. We will also talk about a case study of GPT-3!"> <meta name="twitter:image" content="/assets/img/profile.png"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico?004339841cbc43800ab5ac9276b4716d"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://lars-quaedvlieg.github.io//blog/2024/cs330-stanford-bbml-icl/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "CS-330 Lecture 3: Black-Box Meta-Learning & In-Context Learning",
            "description": "This lecture is part of the CS-330 Deep Multi-Task and Meta Learning course, taught by Chelsea Finn in Fall 2023 at Stanford. The goal of this lecture is to learn how to implement black-box meta-learning techniques. We will also talk about a case study of GPT-3!",
            "published": "March 03, 2024",
            "authors": [
              
              {
                "author": "Lars C.P.M. Quaedvlieg",
                "authorURL": "https://lars-quaedvlieg.github.io/",
                "affiliations": [
                  {
                    "name": "EPFL",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Lars Quaedvlieg </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">Curriculum Vitae </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>CS-330 Lecture 3: Black-Box Meta-Learning &amp; In-Context Learning</h1> <p>This lecture is part of the CS-330 Deep Multi-Task and Meta Learning course, taught by Chelsea Finn in Fall 2023 at Stanford. The goal of this lecture is to learn how to implement black-box meta-learning techniques. We will also talk about a case study of GPT-3!</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#black-box-adaptation-approaches">Black-box adaptation approaches</a> </div> <ul> <li> <a href="#a-more-scalable-architecture">A more scalable architecture</a> </li> <li> <a href="#black-box-adaptation-architectures">Black-box adaptation architectures</a> </li> </ul> <div> <a href="#case-study-of-gpt-3">Case study of GPT-3</a> </div> </nav> </d-contents> <p>The goal of this lecture is to learn how to <strong>implement black-box meta-learning</strong> techniques. We will also talk about a <strong>case study of GPT-3</strong>! If you missed the previous lecture, which was about transfer learning by fine-tuning and meta learning, you can head over <a href="/blog/2024/cs330-stanford-tl-ml/">here</a> to view it.</p> <p>As always, since I am still new to this blogging thing, reach out to me if you have any feedback on my writing, the flow of information, or whatever! You can contact me through <a href="https://www.linkedin.com/in/lars-quaedvlieg/" rel="external nofollow noopener" target="_blank">LinkedIn</a>. ☺</p> <p>The link to the lecture slides can be found <a href="https://cs330.stanford.edu/materials/cs330_metalearning_bbox_2023.pdf" rel="external nofollow noopener" target="_blank">here</a>.</p> <h2 id="black-box-adaptation-approaches">Black-box adaptation approaches</h2> <figure class="figure col-sm-12 float-right"> <img src="/assets/img/blog/cs330/4/omniglot.png" class="img-fluid" alt="Alt text."> <figcaption class="figure-caption text-center">Example of the Omniglot dataset.</figcaption> </figure> <p>The content of this section will build on the general recipe for meta-learning problems that we saw in the previous lecture. In order to explain it, we will use the example of the Omniglot dataset <d-cite key="lake2019omniglot"></d-cite>, which is a dataset of 1,623 characters from 50 different alphabets. In this problem, every alphabet would refer to a different task. In our example, we will do 3-way 1-shot learning, meaning that our sampled datasets consist of 3 classes with 1 example per class at every step. One iteration of the black-box meta-training process then has the following steps:</p> <ol> <li>Sample task $\mathcal{T}_i$ or a mini-batch of tasks. In our case, this would correspond to generating the language(s).</li> <li>From the selected language(s), we sample disjoint datasets $\mathcal{D}_i^\mathrm{tr}$ and $\mathcal{D}_i^\mathrm{test}$ from $\mathcal{D}_i$. In our example, this will be a disjoint dataset with 3 samples of characters for every language alphabet.</li> </ol> <div> <figure class="figure col-sm-5 6 float-right"> <img src="/assets/img/blog/cs330/4/param_lstm.png" class="img-fluid" alt="Alt text."> <figcaption class="figure-caption text-center">Basic model architecture for black-box meta learning.</figcaption> </figure> <p>Now that we have these datasets, our goal is to train a neural network to represent $\phi_i = f_\theta(\mathcal{D}_i^\mathrm{tr})$. After computing these task parameters given a sampled training dataset, we can predict the test targets with $y^\mathrm{ts} = g_{\phi_i}(x^\mathrm{ts})$. An example of how such a model could work, is depicted in the figure above. Here, we are using a sequence model for $f_\theta$, which generates the parameters $\phi_i$. However, you can use all your fancy architectures that can handle a varying number of input sample. This is necessary due to varying dataset lengths.</p> </div> <p>After computing $y^\mathrm{ts}$, we can do backpropagation of the loss that is generated with the this test dataset. The full optimization objective is shown in the equation below:</p> \[\min_\theta \sum_{\mathcal{T}_i} \sum_{(x,y) \sim \mathcal{D}^\mathrm{test}_i} - \log g_{\phi_i}(y\vert x) = \min_\theta \sum_{\mathcal{T}_i}\mathcal{L}(f_\theta(\mathcal{D}^\mathrm{tr}_i), \mathcal{D}^\mathrm{test}_i)\;.\] <p>Notice that we are optimizing the parameters $\theta$. The task-specific parameters $\phi_i$ are generated by $f_\theta(\mathcal{D}_i^\mathrm{tr})$, and so they are not updated. Also note that the loss is calculated with respect to the sampled <strong>test dataset</strong>! This is no problem, since it makes sense to evaluate on new tasks for meta learning.</p> <p>Now that you understand the architecture, we can write down the last two steps of the meta-training process:</p> <ol> <li>Compute $\phi_i \leftarrow f_\theta(\mathcal{D}_i^\mathrm{tr})$.</li> <li>Update $\theta$ using $\nabla_\theta \mathcal{L}(\phi_i, \mathcal{D}_i^\mathrm{test})$.</li> </ol> <h3 id="a-more-scalable-architecture">A more scalable architecture</h3> <p>However, we run into an issue. How do we let the model $f_\theta$ output another model’s parameters $\phi_i$? Not only can this be quite tricky to do, it also does not scale to larger parameter vectors $\phi_i$! Can you think of an alternative way of going this?</p> <figure class="figure col-sm-12 float-right"> <img src="/assets/img/blog/cs330/4/better_model.png" class="img-fluid" alt="Alt text."> <figcaption class="figure-caption text-center">More scalable architecture for black-box meta-learning.</figcaption> </figure> <p>Instead of letting $f_\theta$ output $\phi_i$, we instead output a hidden state $h_i$, which is a low-dimensional vector that is supposed to represent contextual task information from the training dataset. If you recall the different ways of conditioning that we saw for multi-task learning, you can see that we can train a model end-to-end by conditioning as $y^\mathrm{ts} = g_{\phi}(x^\mathrm{ts} \vert h_i)$. Now, notice that we have a general set of parameters $\phi$ for $g$; it does not need to be task-specific anymore, since we are already conditioning on task information. In the figure above, $\theta$ are the parameters of the sequence model, and $\phi$ are the parameters of the convolutional network.</p> <p>❗One problem that sometimes occurs with this architecture, is that the model learns to <strong>ignore conditioning on $h_i$.</strong> In that case, it is essentially just learning to memorize, and not using the training dataset. In order to avoid that, you can randomize the numerical label assignment to the target variables when sampling the datasets $\mathcal{D}^{tr}_i$ and $\mathcal{D}^{test}_i$. If the numerical label is different each time, it cannot just memorize the sample from the testing set.</p> <h3 id="black-box-adaptation-architectures">Black-box adaptation architectures</h3> <p>The architecture that we just presented was more-or-less first proposed on the Omniglot dataset at ICML in 2016 <d-cite key="santoro2016meta"></d-cite>. It used LSTMs with Neural Turing Machines (which are not used anymore nowadays). Since then, a lot of new architectures have been proposed.</p> <p>At ICML 2018, an architecture called the DeepSet architecture <d-cite key="garnelo2018conditional"></d-cite> was published. The idea is to pass all your dataset samples through a feedforward neural network to get an embedding of each sample, and then average those. This way, you have a permutation-invariant model which is still model-agnostic. Given some conditions on the width and depth of the network, these models can represent any permutation-invariant function.</p> <p>There are quite some more papers that used other external memory mechanisms <d-cite key="munkhdalai2017meta"></d-cite>, or convolutions and attention <d-cite key="mishra2017simple"></d-cite>.</p> <p>Unfortunately, these models are still quite limited in capabilities against “difficult” datasets, as you can see in the table below.</p> <figure class="figure col-sm-12 float-right"> <img src="/assets/img/blog/cs330/4/bmml_results.png" class="img-fluid" alt="Alt text."> <figcaption class="figure-caption text-center">Results of a model trained with black-box meta-learning.</figcaption> </figure> <p>In summary, some benefits of black-box meta learning are its <strong>expressiveness</strong>, how easy it is to combine with a <strong>variety of learning problems</strong> (such as SL or RL). Nonetheless, it is a <strong>challenging optimization problem</strong> for a <strong>complex model</strong>, and it is often <strong>data-inefficient</strong>.</p> <hr> <h2 id="case-study-of-gpt-3">Case study of GPT-3</h2> <p>With the rise of research on in-context learning, especially with foundation models, GPT-3 <d-cite key="brown2020language"></d-cite> is a good example of a black-box meta-learner, trained on language generation tasks. We can represent the task-specific datasets $\mathcal{D}_i^\mathrm{tr}$ as a sequence of characters, and $\mathcal{D}_i^\mathrm{test}$ as the following sequence of characters. This way, $\mathcal{D}_i^\mathrm{tr}$ is what the model is being conditioned on (its context), and $\mathcal{D}_i^\mathrm{test}$ is what it has to generate.</p> <p>The meta-training dataset consists of crawled data from the internet, English-language Wikipedia, and two books corpora, with a giant Transformer architecture as its network (175 billion parameters, 96 layers, 3.2M batch size).</p> <p>For these datasets, there are a multitude of different tasks such as, but definitely not limited to, <strong>spelling correction</strong>, <strong>simple math problems</strong>, or <strong>translating between languages</strong>. By encoding every task as text, the authors are able to obtain meta-training data incredibly easily.</p> <figure class="figure col-sm-12 float-right"> <img src="/assets/img/blog/cs330/4/gpt3_pipeline.png" class="img-fluid" alt="Alt text."> <figcaption class="figure-caption text-center">Abstract representation of the training meta-train pipeline of GPT-3.</figcaption> </figure> <p>In the case of GPT-3, text generation, also known as in-context learning, represents the inner loop of the optimization process. The outer loop represents the model optimizing across different tasks, which is very similar to the process that we saw in the previous section.</p> <p>With this model, you can easily do few-shot learning by adding examples in text form to the context of the model. Even through the model is far from perfect, its results are extremely impressive. It is also no oracle and can fail in unintuitive ways! If there is anything we have learned from recent research, it is that <strong>the choice of $\mathcal{D}^\mathrm{tr}$ at test time matters</strong> (welcome to the world of prompt engineering).</p> <p>It is also interesting to think about what is needed for <strong>few-shot learning to emerge</strong> when training a model. This is an active research are, but it seems that (1) temporal correlation in your data with dynamic meaning of words, and (2) large model capacities definitely seems to make a difference here <d-cite key="chan2022data"></d-cite>.</p> <hr> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/blog/cs330/2024-03-03-bbml-icl.bib"></d-bibliography> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Lars C.P.M. Quaedvlieg. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a>. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-JKH10LEP3Y"></script> <script defer src="/assets/js/google-analytics-setup.js"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>